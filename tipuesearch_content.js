var tipuesearch = {"pages":[{"title":"高效去重算法Bloomfilter","text":"基于redis实现Bloomfilter #!usr/bin/env python # -*- coding:utf-8 -*- \"\"\" @author: nico @file: bloomfilter_redis.py @time: 2018/08/31 \"\"\" import math import mmh3 class BloomFilter : def __init__ ( self , n , f , server , block_num = 1 , key_prefix = 'BLOOMFILTER' ): \"\"\" m: number of bit as least to be assign k: number of hash as least need :param n: number of items is going to add :param f: expected false positive probability :param server: the redis client instance :param block_num: number of redis block, one of block maxsize 512m , 2**32 :param key_prefix: the block key prefix \"\"\" if not ( 0 < f < 1 ): raise ValueError ( \"f must be between 0 and 1.\" ) if not n > 0 : raise ValueError ( \"n must be > 0\" ) self . n = n self . f = f self . k = math . ceil ( math . log ( 1.0 / f , 2 )) self . m = 1 << 31 # 2**32 self . server = server self . key_prefix = key_prefix self . block_num = block_num def __contains__ ( self , item ): item = str ( item ) key = self . __get_block_route_key ( item ) res = True for seed in range ( self . k ): offset = mmh3 . hash ( item , seed , signed = False ) res = res & self . server . getbit ( key , offset % self . m ) return True if res else False def add ( self , item ): item = str ( item ) self . key = self . __get_block_route_key ( item ) for seed in range ( self . k ): offset = mmh3 . hash ( item , seed , signed = False ) self . server . setbit ( self . key , offset % self . m , 1 ) def __get_block_route_key ( self , hashable ): return self . key_prefix + str ( sum ( map ( ord , hashable )) % self . block_num ) if __name__ == '__main__' : from redis import StrictRedis client = StrictRedis () bf = BloomFilter ( 100000000 , 0.0001 , client ) test_str = [ \"python\" , \"c\" , \"c++\" , \"ruby\" ] for el in test_str : bf . add ( el ) print ( list ( map ( lambda _ : _ in bf , [ 'lua' , 'python' , 'go' , 'c' ]))) # [False, True, False, True] 基于内存实现Bloomfilter #!usr/bin/env python # -*- coding:utf-8 -*- \"\"\" @author: nico @file: bloomfilter_memory.py @time: 2018/08/31 \"\"\" import math import mmh3 import bitarray class BloomFilter : def __init__ ( self , n , f , block_num = 1 ): \"\"\" m: number of bit as least to be assign k: number of hash as least need :param n: number of items is going to add :param f: expected false positive probability :param block_num: number of bitarray obj, one block maxsize 16Gb on 32 bit systems \"\"\" if not ( 0 < f < 1 ): raise ValueError ( \"f must be between 0 and 1.\" ) if not n > 0 : raise ValueError ( \"n must be > 0\" ) self . n = n self . f = f self . k = math . ceil ( math . log ( 1.0 / f , 2 )) self . m = math . ceil ( - self . k / math . log ( 1 - math . exp ( math . log ( f ) / self . k )) * n ) self . block_num = block_num self . store = { i : bitarray . bitarray ( self . m , endian = 'little' ) for i in range ( self . block_num )} for el in self . store . values (): el . setall ( False ) def __contains__ ( self , item ): item = str ( item ) flag = True for seed in range ( self . k ): offset = mmh3 . hash ( item , seed , signed = False ) flag = flag & self . store [ offset % self . block_num ][ offset % self . m ] return True if flag else False def add ( self , item ): item = str ( item ) for seed in range ( self . k ): offset = mmh3 . hash ( item , seed , signed = False ) self . store [ offset % self . block_num ][ offset % self . m ] = 1 if __name__ == \"__main__\" : bf = BloomFilter ( 100000000 , 0.0001 , block_num = 2 ) test_str = [ \"python\" , \"c\" , \"c++\" , \"ruby\" , 1 , 2 , 3 ] for el in test_str : bf . add ( el ) print ( list ( map ( lambda _ : _ in bf , [ 'lua' , 'python' , 'go' , 'c' , 4 , 2 , 1 ]))) # [False, True, False, True, False, True, True]","tags":"Algorithms","url":"/bloomfilter","loc":"/bloomfilter"},{"title":"NodeJs开发环境搭建实践","text":"注解 本开发搭建实践指南中所有示例代码采自 《Learning JavaScript》第三版 英文原书中， 由于书中工具集可能比较旧，所以在安装对应工具集时，确认好版本。 开始前新建一个项目目录，并运行下面指令初始化项目目录 npm init 开发工具集合 Node 允许脱离浏览器运行 javascript 脚本 Gulp 自动化构建工具 Babel javascript 语法转译器， 支持 ES6 -> ES5 语法转换 ESLint javascript 代码检查，让你避免常见错误，保证代码健壮性 NodeJs版本 nicodeMacBook-Pro:GitHub nico$ node -v v12.13.0 nicodeMacBook-Pro:GitHub nico$ npm -v 6.12.0 安装 Gulp 自动化构建工具 全局安装 gulp (只安装一次？) nicodeMacBook-Pro:GitHub nico$ npm install -g gulp /usr/local/bin/gulp -> /usr/local/lib/node_modules/gulp/bin/gulp.js > fsevents@1.2.9 install /usr/local/lib/node_modules/gulp/node_modules/fsevents > node install node-pre-gyp WARN Using needle for node-pre-gyp https download [fsevents] Success: \"/usr/local/lib/node_modules/gulp/node_modules/fsevents/lib/binding/Release/node-v72-darwin-x64/fse.node\" is installed via remote + gulp@4.0.2 added 384 packages from 238 contributors in 14.761s nicodeMacBook-Pro:GitHub nico$ gulp -v CLI version: 2.2.0 Local version: Unknown 安装完成后，在项目根目录安装项目本地的 gulp nicodeMacBook-Pro:NodePractice nico$ npm --save-dev install gulp 测试 gulp 是否正常工作,在项目根目录下新建 gulpfile.js nicodeMacBook-Pro:NodePractice nico$ ls gulpfile.js node_modules package-lock.json gulpfile.js const gulp = require ( 'gulp' ); // Gulp dependencies go here gulp . task ( 'default' , function () { // Gulp tasks go here }); 直接执行 gulp nicodeMacBook-Pro:NodePractice nico$ gulp [21:33:29] Using gulpfile ~/GitHub/NodePractice/gulpfile.js [21:33:29] Starting 'default'... [21:33:29] The following tasks did not complete: default [21:33:29] Did you forget to signal async completion? 似乎报错了，应该是示例代码太老了，可以参考 这篇文章的解决办法 安装 Babel npm install --save-dev gulp-babel @babel/core @babel/preset-env 创建 .babelrc, 加入下面 babel 配置。 { \"presets\" : [ \"@babel/preset-env\" ] } 测试 babel 是否正常工作，打开 gulpfile.js 加入下面代码。 const gulp = require ( 'gulp' ); const babel = require ( 'gulp-babel' ); // Gulp dependencies go here gulp . task ( 'default' , function () { // Gulp tasks go here gulp . src ( \"es6/**/*.js\" ) . pipe ( babel ()) . pipe ( gulp . dest ( \"dist\" )); // browser source gulp . src ( \"public/es6/**/*.js\" ) . pipe ( babel ()) . pipe ( gulp . dest ( \"public/dist\" )); }); 在 es6 目录下新建一个 test.js 文件。 'use strict' ; // es6 feature: block-scoped \"let\" declaration const sentences = [ { subject : 'JavaScript' , verb : 'is' , object : 'great' }, { subject : 'Elephants' , verb : 'are' , object : 'large' }, ]; // es6 feature: object destructuring function say ({ subject , verb , object }) { // es6 feature: template strings console . log ( ` ${ subject } ${ verb } ${ object } ` ); } // es6 feature: for..of for ( let s of sentences ) { say ( s ); } 最后在项目根目录执行 gulp, 后会发现在 dist 目录下生成对应 es5 脚本文件。 'use strict' ; // es6 feature: block-scoped \"let\" declaration var sentences = [{ subject : 'JavaScript' , verb : 'is' , object : 'great' }, { subject : 'Elephants' , verb : 'are' , object : 'large' }]; // es6 feature: object destructuring function say ( _ref ) { var subject = _ref . subject , verb = _ref . verb , object = _ref . object ; // es6 feature: template strings console . log ( \"\" . concat ( subject , \" \" ). concat ( verb , \" \" ). concat ( object )); } // es6 feature: for..of for ( var _i = 0 , _sentences = sentences ; _i < _sentences . length ; _i ++ ) { var s = _sentences [ _i ]; say ( s ); } 使用 node 执行在 dist 目录转译后的 test.js 文件 nicodeMacBook-Pro:NodePractice nico$ node dist/test.js JavaScript is great Elephants are large 安装 ESLint npm install -g eslint /usr/local/bin/eslint -> /usr/local/lib/node_modules/eslint/bin/eslint.js + eslint@6.6.0 added 121 packages from 75 contributors in 5.228s 在项目根目录下通过下面指令生成 .eslintrc 文件。 eslint --init 警告 在运行上面指令时，确保项目根目录下存在 package.json 文件，如果不存在，请首先通过以下指令进行生成。 npm init 安装 gulp-eslint nicodeMacBook-Pro:NodePractice nico$ npm install --save-dev gulp-eslint npm WARN eslint-plugin-vue@5.2.3 requires a peer of eslint@&#94;5.0.0 but none is installed. You must install peer dependencies yourself. npm WARN gulp-babel@8.0.0 requires a peer of @babel/core@&#94;7.0.0 but none is installed. You must install peer dependencies yourself. npm WARN tsutils@3.17.1 requires a peer of typescript@>=2.8.0 || >= 3.2.0-dev || >= 3.3.0-dev || >= 3.4.0-dev || >= 3.5.0-dev || >= 3.6.0-dev || >= 3.6.0-beta || >= 3.7.0-dev || >= 3.7.0-beta but none is installed. You must install peer dependencies yourself. npm WARN vue-eslint-parser@5.0.0 requires a peer of eslint@&#94;5.0.0 but none is installed. You must install peer dependencies yourself. npm WARN nodepractice@1.0.0 No description npm WARN nodepractice@1.0.0 No repository field. + gulp-eslint@6.0.0 added 1 package from 2 contributors in 2.053s 修改项目根目录下的 gulp.js const gulp = require ( 'gulp' ); const babel = require ( 'gulp-babel' ); const eslint = require ( 'gulp-eslint' ); gulp . task ( 'default' , function () { // Run ESLint gulp . src ([ \"es6/**/*.js\" , \"public/es6/**/*.js\" ]) . pipe ( eslint ()) . pipe ( eslint . format ()); // Node source gulp . src ( \"es6/**/*.js\" ) . pipe ( babel ()) . pipe ( gulp . dest ( \"dist\" )); // browser source gulp . src ( \"public/es6/**/*.js\" ) . pipe ( babel ()) . pipe ( gulp . dest ( \"public/dist\" )); }); 项目根目录下执行 gulp nicodeMacBook-Pro:NodePractice nico$ gulp [23:52:40] Using gulpfile ~/GitHub/NodePractice/gulpfile.js [23:52:40] Starting 'default'... [23:52:40] /Users/nico/GitHub/NodePractice/es6/test.js 1:13 error Extra semicolon semi 4:1 error Expected indentation of 2 spaces but found 8 indent 5:1 error Expected indentation of 2 spaces but found 8 indent 5:63 error Unexpected trailing comma comma-dangle 6:2 error Extra semicolon semi 8:13 error Missing space before function parentheses space-before-function-paren 9:1 error Expected indentation of 2 spaces but found 5 indent 9:38 error Trailing spaces not allowed no-trailing-spaces 10:1 error Expected indentation of 2 spaces but found 5 indent 10:49 error Extra semicolon semi 13:1 error Expected space(s) after \"for\" keyword-spacing 13:9 error 's' is never reassigned. Use 'const' instead prefer-const 14:1 error Expected indentation of 2 spaces but found 5 indent 14:12 error Extra semicolon semi ✖ 14 problems (14 errors, 0 warnings) 14 errors and 0 warnings potentially fixable with the `--fix` option. NodeJs工程结构 如下 dist 目录用于存放 node 服务端 es6 转译后的 es5 代码，es6 目录存放 node 服务端代码， public/es6，及 public/dist 分别存放浏览器端的 es6 代码，和 es5 代码。 . ├── dist ├── es6 ├── gulpfile.js ├── node_modules ├── package-lock.json ├── package.json └── public ├── dist └── es6 最后到这，就可以进行基本 Node 开发了。","tags":"Nodejs","url":"/nodejs_practice","loc":"/nodejs_practice"},{"title":"ScrapyRedis集成Bloomfilter","text":"新建 dupfilters package #!usr/bin/env python #-*- coding:utf-8 -*- \"\"\" @author: nico @file: __init__.py @time: 2018/08/31 \"\"\" import os import logging from scrapy.dupefilters import BaseDupeFilter , RFPDupeFilter from scrapy.utils.request import request_fingerprint from scrapy.utils.job import job_dir from scrapy_redis.connection import get_redis_from_settings from robot.dupefilters import bloomfilter_memory , bloomfilter_redis logger = logging . getLogger ( 'dupefilters' ) class BloomFilterRedis ( BaseDupeFilter ): def __init__ ( self , n = 100000000 , f = 0.0001 , server = None , block_nums = 1 , key_prefix = 'BLOOMFILTER' , * args , ** kwargs ): self . bf = bloomfilter_redis . BloomFilter ( n , f , server , block_nums , key_prefix ) self . debug = kwargs . get ( 'debug' , True ) self . logdupes = True @classmethod def from_settings ( cls , settings ): server = get_redis_from_settings ( settings ) key_prefix = settings . get ( \"BLOOMFILTER_REDIS_KEY_PREFIX\" , \"BLOOMFILTER\" ) capacity = settings . get ( \"BLOOMFILTER_REDIS_CAPACITY\" , 100000000 ) error_rate = settings . get ( \"BLOOMFILTER_REDIS_FALSE_POSITIVE_PROBABILITY\" , 0.0001 ) block_nums = settings . get ( \"BLOOMFILTER_REDIS_BLOCK_NUMS\" , 1 ) debug = settings . getbool ( 'DUPEFILTER_DEBUG' , False ) return cls ( capacity , error_rate , server , block_nums , key_prefix , debug = debug ) @classmethod def from_spider ( cls , spider ): settings = spider . settings server = get_redis_from_settings ( settings ) key_prefix = settings . get ( \"BLOOMFILTER_REDIS_KEY_PREFIX\" , \"BLOOMFILTER\" ) capacity = settings . get ( \"BLOOMFILTER_REDIS_CAPACITY\" , 100000000 ) error_rate = settings . get ( \"BLOOMFILTER_REDIS_FALSE_POSITIVE_PROBABILITY\" , 0.0001 ) block_nums = settings . get ( \"BLOOMFILTER_REDIS_BLOCK_NUMS\" , 1 ) debug = settings . getbool ( 'DUPEFILTER_DEBUG' , False ) return cls ( capacity , error_rate , server , block_nums , key_prefix , debug = debug ) @classmethod def from_crawler ( cls , crawler ): return cls . from_settings ( crawler . settings ) def request_seen ( self , request ): fp = request_fingerprint ( request ) if fp in self . bf : return True else : self . bf . add ( fp ) return False def open ( self ): pass def close ( self , reason ): if self . bf . key : self . bf . server . delete ( self . bf . key ) def log ( self , request , spider ): if self . debug : msg = \"Filtered duplicate request: %(request)s \" logger . debug ( msg , { 'request' : request }, extra = { 'spider' : spider }) elif self . logdupes : msg = ( \"Filtered duplicate request %(request)s \" \" - no more duplicates will be shown\" \" (see DUPEFILTER_DEBUG to show all duplicates)\" ) logger . debug ( msg , { 'request' : request }, extra = { 'spider' : spider }) self . logdupes = False @classmethod def from_crawler ( cls , crawler ): return cls . from_settings ( crawler . settings ) def request_seen ( self , request ): fp = request_fingerprint ( request ) if fp in self . bf : return True else : self . bf . add ( fp ) if self . file : self . file . write ( fp + os . linesep ) return False def log ( self , request , spider ): if self . debug : msg = \"Filtered duplicate request: %(request)s \" logger . debug ( msg , { 'request' : request }, extra = { 'spider' : spider }) elif self . logdupes : msg = ( \"Filtered duplicate request %(request)s \" \" - no more duplicates will be shown\" \" (see DUPEFILTER_DEBUG to show all duplicates)\" ) logger . debug ( msg , { 'request' : request }, extra = { 'spider' : spider }) self . logdupes = False 重构ScrapyRedis调度器 #!usr/bin/env python # -*- coding:utf-8 -*- \"\"\" @author: nico @file: schedulers.py @time: 2018/09/02 \"\"\" from scrapy.utils.misc import load_object from scrapy_redis import scheduler as redis_scheduler from scrapy.core import scheduler class RedisScheduler ( redis_scheduler . Scheduler ): def open ( self , spider ): self . spider = spider try : self . queue = load_object ( self . queue_cls )( server = self . server , spider = spider , key = self . queue_key % { 'spider' : spider . name }, serializer = self . serializer , ) except TypeError as e : raise ValueError ( \"Failed to instantiate queue class ' %s ': %s \" , self . queue_cls , e ) try : self . df = load_object ( self . dupefilter_cls )( capacity = spider . settings . get ( \"BLOOMFILTER_REDIS_CAPACITY\" , 100000000 ), error_rate = spider . settings . get ( \"BLOOMFILTER_REDIS_FALSE_POSITIVE_PROBABILITY\" , 0.0001 ), server = self . server , key_prefix = self . dupefilter_key % { 'spider' : spider . name }, block_nums = spider . settings . get ( \"BLOOMFILTER_REDIS_BLOCK_NUMS\" , 1 ), debug = spider . settings . getbool ( 'DUPEFILTER_DEBUG' ), ) except TypeError as e : raise ValueError ( \"Failed to instantiate dupefilter class ' %s ': %s \" , self . dupefilter_cls , e ) if self . flush_on_start : self . flush () # notice if there are requests already in the queue to resume the crawl if len ( self . queue ): spider . log ( \"Resuming crawl ( %d requests scheduled)\" % len ( self . queue )) 在 settings.py 中添加类似如下的配置 SCHEDULER = \"robot.schedulers.RedisScheduler\" DUPEFILTER_CLASS = \"robot.dupefilters.BloomFilterRedis\"","tags":"Scrapy","url":"/scrapyredis-bloomfilter","loc":"/scrapyredis-bloomfilter"}]};